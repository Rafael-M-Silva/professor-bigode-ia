````md
# ğŸ‘¨â€ğŸ« Professor Bigode IA

Chatbot em forma de â€œprofessor de programaÃ§Ã£oâ€ que responde dÃºvidas tÃ©cnicas com a personalidade do **Professor Bigode**: direto, didÃ¡tico e sem enrolaÃ§Ã£o.

> ğŸ”— Deploy: https://professor-bigode-ia.vercel.app  

O objetivo do projeto Ã© servir como laboratÃ³rio para estudar **Next.js + IA + RAG**, alÃ©m de ser um assistente para alunos tirarem dÃºvidas sobre lÃ³gica, JavaScript, front-end e carreira.

---

## âœ¨ Funcionalidades

- ğŸ’¬ **Chat em tempo real** com interface simples e responsiva
- ğŸ‘¨â€ğŸ« **Persona fixa do Professor Bigode** (via `SYSTEM_PROMPT`)
- ğŸ“š **RAG bÃ¡sico** usando um arquivo de conhecimento (`KNOWLEDGE`) com contexto adicional
- ğŸ§  Uso de **Ollama Cloud** como LLM (modelo `gpt-oss:120b-*`)
- ğŸ§µ Suporte a **histÃ³rico de conversa** (`history`) enviado para a API
- â˜ï¸ **Deploy na Vercel** usando apenas o prÃ³prio Next (API Routes + Front)

---

## ğŸ§± Stack utilizada

- [Next.js (App Router) + TypeScript](https://nextjs.org/)
- React 18
- Tailwind CSS
- [Ollama Cloud](https://ollama.com/) â€“ modelo `gpt-oss:120b-*`
- Node.js 18+ / 20+

---

## ğŸ“‚ Estrutura do projeto (resumida)

```bash
professor-bigode-ia/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚       â””â”€â”€ route.ts      # Rota da API que conversa com o Ollama
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Chat.tsx          # Componente principal do chat
â”‚   â”‚   â””â”€â”€ ...               # Outros componentes (BG, Button, etc.)
â”‚   â””â”€â”€ page.tsx              # PÃ¡gina inicial que renderiza o chat
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ systemPrompt.ts       # Persona do Professor Bigode (SYSTEM_PROMPT)
â”‚   â””â”€â”€ knowledge.ts          # Base de conhecimento (KNOWLEDGE) usada no RAG
â”œâ”€â”€ public/                   # Imagens, favicons, etc.
â”œâ”€â”€ package.json
â”œâ”€â”€ next.config.ts
â””â”€â”€ tailwind.config.js
````

> Os nomes podem variar um pouco conforme as prÃ³ximas refatoraÃ§Ãµes, mas a ideia geral Ã© essa:
> **front + API no Next + camada de RAG em arquivos separados.**

---

## âš™ï¸ ConfiguraÃ§Ã£o do ambiente

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/Rafael-M-Silva/professor-bigode-ia.git
cd professor-bigode-ia
```

### 2. Instalar dependÃªncias

```bash
npm install
# ou
yarn
# ou
pnpm install
```

### 3. VariÃ¡veis de ambiente

Crie um arquivo `.env.local` na raiz do projeto com:

```env
OLLAMA_API_KEY=SEU_TOKEN_DA_OLLAMA_AQUI
```

Se vocÃª estiver usando uma URL especÃ­fica de API, tambÃ©m pode adicionar (opcional):

```env
NEXT_PUBLIC_API_URL=/api/chat
```

> Em produÃ§Ã£o (Vercel), configure as mesmas variÃ¡veis em **Settings â†’ Environment Variables**.

---

## ğŸ§  Rota da API (`/api/chat`)

A rota da API recebe a mensagem do usuÃ¡rio e o histÃ³rico da conversa, monta o contexto com o `SYSTEM_PROMPT` + `KNOWLEDGE` e envia para o modelo da Ollama.

### Request

`POST /api/chat`

```json
{
  "message": "Professor, explica o que Ã© hoisting em JavaScript?",
  "history": [
    { "role": "user", "content": "Pode me ajudar com JavaScript?" },
    { "role": "assistant", "content": "Bora, manda a dÃºvida." }
  ]
}
```

### Response (exemplo)

```json
"Hoisting Ã© o comportamento do JavaScript de mover declaraÃ§Ãµes para o topo do escopo..."
```

> Obs.: a resposta atualmente Ã© enviada como **string simples** (`response.message.content`).
> Pode ser alterado depois para um objeto `{ "reply": "..." }` se fizer sentido.

---

## ğŸ’» Rodando o projeto em desenvolvimento

```bash
npm run dev
```

Acesse:

> [http://localhost:3000](http://localhost:3000)

---

## ğŸš€ Deploy

O projeto estÃ¡ configurado para deploy na **Vercel**:

1. Conectar o repositÃ³rio no painel da Vercel
2. Configurar as variÃ¡veis de ambiente (`OLLAMA_API_KEY`, etc.)
3. Deploy automÃ¡tico via push na branch (`main`, `staging`, etc.)

A rota `/api/chat` Ã© servida pelo prÃ³prio Next.js, entÃ£o o front consome diretamente `"/api/chat"` no mesmo domÃ­nio.

---

## ğŸ§­ PrÃ³ximos passos / ideias

* [ ] Adicionar **streaming de respostas** (para nÃ£o esperar o texto todo)
* [ ] Salvar conversas em algum storage (Supabase / Mongo / etc.)
* [ ] Criar aba de **configuraÃ§Ãµes** para trocar modelo/persona
* [ ] Melhorar o RAG (leitura de arquivos externos / markdown / PDFs)
* [ ] Adicionar testes bÃ¡sicos (unitÃ¡rio e de integraÃ§Ã£o da rota `/api/chat`)

---

## ğŸ‘¨â€ğŸ« Sobre o Professor Bigode

Projeto criado por **Rafael Mauricio** como laboratÃ³rio de:

* IA aplicada ao ensino de programaÃ§Ã£o
* IntegraÃ§Ã£o de LLMs com front-end moderno
* Experimentos com RAG e personas para educaÃ§Ã£o
